\documentclass{beamer}

\input{../defs.tex}

% workaround for beamer bug
\providecommand\thispdfpagelabel[1]{}  % workaround

% presentation
\mode<presentation>
{
  \usetheme{Warsaw}
  % or ...

  \setbeamercovered{transparent}
  % or whatever (possibly just delete it)
}


\usepackage[english]{babel}
% or whatever

\usepackage[latin1]{inputenc}
% or whatever

\usepackage{times}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.


\title[Variational] % (optional, use only with long paper titles)
{Variational Methods}

% \subtitle
% {The subtitle} % (optional)

\author% [Holmes] (optional, use only with lots of authors)
{I.~Holmes} % \inst{1} \and S.~Another\inst{2}
% - Use the \inst{?} command only if the authors have different
%   affiliation.

\institute[University of California, Berkeley] % (optional, but mostly needed)
{
%  \inst{1}%
  Department of Bioengineering\\
  University of California, Berkeley}
% - Use the \inst command only if there are several affiliations.
% - Keep it simple, no one is interested in your street address.

\date%[Short Occasion] % (optional)
{Spring semester}

\subject{Talks}
% This is only inserted into the PDF information catalog. Can be left
% out. 



% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% \pgfdeclareimage[height=0.5cm]{university-logo}{university-logo-filename}
% \logo{\pgfuseimage{university-logo}}



% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
\AtBeginSubsection[]
{
  \begin{frame}<beamer>{Outline}
    \tableofcontents[currentsection,currentsubsection]
  \end{frame}
}


% If you wish to uncover everything in a step-wise fashion, uncomment
% the following command: 

%\beamerdefaultoverlayspecification{<+->}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}

\begin{frame}{Outline}
  \tableofcontents
  % You might wish to add the option [pausesections]
\end{frame}

\section{The variational approximation}

\begin{frame}{General form}

Let $(x,y)$ denote hidden \& observed data.

Let $P(x,y|\theta)$ be the ``true'' likelihood model, \\
implying an evidence $P(y|\theta)$ for the observed data, \\
and a posterior distribution $P(x|y,\theta)$ over the hidden data.

Let $q(x|\phi)$ be a separable approximation to this posterior,
using variational parameters $\phi$
to approximate the pair $(y,\theta)$.

With $\langle f \rangle_q \equiv \sum_x q(x|\phi) f(x,\ldots)$, define
\begin{eqnarray*}
L(y;\theta,\phi) & = & \log P(y|\theta) - D\left(q||P(x|y,\theta)\right) \\
& = & \langle \log P(x,y|\theta) \rangle_q + S\left( q \right)
\end{eqnarray*}

where $S(q) = -\langle \log q \rangle_q$ is the Shannon entropy
and $D(q||r) = \langle \log (q/r) \rangle_q$ is the relative entropy.

\end{frame}


\begin{frame}{Variational lower bound}

\begin{eqnarray*}
L(y;\theta,\phi) & = & \log P(y|\theta) - D\left(q||P(x|y,\theta)\right) \\
& = & \langle \log P(x,y|\theta) \rangle_q + S\left( q \right)
\end{eqnarray*}

By Gibbs' inequality ($D(q||r) \geq 0$), $L$ is a lower bound for the log-likelihood ($\log P(y|\theta)$).
The variational lower bound is the highest that we can get this lower bound

\[
L^\ast(y;\theta) = \max_{\phi} L(y;\theta,\phi) = L(y;\theta,\phi^\ast)
\]

Doing this effectively seems to require
 a $q(x|\phi)$ that is a sufficiently flexible fit to $P(x|y,\theta)$,
 a closed form for $L = \langle \log P(x,y|\theta) \rangle_q + S(q)$,
 and an approach to solving $\frac{\partial{L}}{\partial{\phi}} = 0$.

\end{frame}


\end{document}
